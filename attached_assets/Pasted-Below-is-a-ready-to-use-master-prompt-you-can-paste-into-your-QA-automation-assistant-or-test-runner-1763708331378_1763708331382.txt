Below is a ready-to-use master prompt you can paste into your QA automation assistant or test runner to generate a complete test plan and scripts. It covers frontend, backend, and end-to-end testing with clear outputs and acceptance criteria. Replace the placeholders in braces with your values.

Title: Master QA Prompt for Frontend, Backend, and E2E Testing

Context

Product: Scholar AI Advisor, www.scholaraiadvisor.com
Mission alignment: Validate a high-quality, accessible, performant, and secure experience for students and providers that supports 99.9% uptime and ~120ms P95 API latency targets.
Objective: Produce a comprehensive, automated, and data-driven test suite that reduces regressions, ensures cross-browser/device consistency, and safeguards data integrity and security.
Environment and Inputs

App URLs:
Web app base: {APP_URL}
API base: {API_BASE_URL}
Staging env: {STAGING_URL}
Test Accounts:
Student: {EMAIL_STUDENT} / {PASSWORD_STUDENT}
Provider: {EMAIL_PROVIDER} / {PASSWORD_PROVIDER}
Admin (if applicable): {EMAIL_ADMIN} / {PASSWORD_ADMIN}
Browsers and Devices:
Desktop: Chrome latest, Firefox latest, Safari latest
Mobile: iOS Safari latest, Android Chrome latest
Viewports: 320x568, 390x844, 768x1024, 1366x768, 1920x1080
Tools and Framework Preferences:
Frontend unit/integration: Jest + React Testing Library (or Vue/Test Utils), MSW for mocks
E2E: Playwright or Cypress
Accessibility: axe-core; manual checks with NVDA and VoiceOver guidelines
Visual regression: Percy or Applitools
Performance: Lighthouse CI for frontend; k6 or Locust for backend/APIs
API testing: Postman/Newman or REST-assured
Compliance and Ethics:
Ensure WCAG 2.1 AA accessibility coverage
Respect FERPA/COPPA-aligned data handling in tests
No real PII; use synthetic data and environment-specific test fixtures
Primary Deliverables (produce all)

Test Plan and Coverage Matrix

Map test types to app areas: onboarding, scholarship search, application builder, essay guidance, payment/credits, provider dashboard, settings/profile, notifications.
For each area, list test categories: unit, integration, functional, visual, accessibility, performance, cross-browser, API, database, security, E2E.
Include risk ranking and prioritization (P0, P1, P2).
Frontend Tests

Unit tests: buttons, input fields, forms, modals, toasts, pagination, filters, accessibility hooks, error states.
Integration tests: search form + results list + pagination; application form + validation + submission flow; payment modal + confirmation.
Functional tests: key user journeys
Student: sign up/login, complete profile, search and filter scholarships, save items, start and submit an application, purchase credits, receive confirmation.
Provider: login, create and publish scholarship, review submissions, message applicants.
Visual tests: baseline snapshots across specified viewports and themes; fail on >0% diff unless explicitly approved.
Accessibility tests: axe violations must be 0 critical/serious; verify focus order, landmarks, labels, color contrast, keyboard-only navigation, screen reader names/roles/values; include ARIA live region checks for form errors.
Cross-browser/device tests: same functional suite runs on all listed browsers/devices.
Backend Tests

Unit tests: business logic helpers, validation, scoring/ranking.
API tests: auth, scholarship search/filter endpoints, application CRUD, file upload, payment/credits, notifications; verify status codes, schemas, pagination, error handling, and rate limiting.
Database tests: CRUD integrity, transactional behavior, migrations, indexes for query performance.
Security tests: authentication and authorization enforcement, input validation, SQLi/XSS payloads, IDOR checks, CSRF where applicable, secrets/config hygiene.
Performance/load tests: define targets and run scenarios
API P95 latency: ≤120ms for read endpoints, ≤250ms for write endpoints in staging baseline.
Throughput goal: {TARGET_RPS} sustained for {DURATION} with error rate <0.5%.
Soak test: {RPS_SOAK} for {SOAK_DURATION} to detect memory leaks.
End-to-End (E2E) Tests

Student flow: create account → verify email (stub if needed) → complete profile → search and filter → select scholarship → fill application → upload essay/file → review and submit → receive confirmation → see status in dashboard.
Provider flow: login → create scholarship with criteria → publish → verify discoverability → review incoming applications → change status → notify student.
Data assertions: verify DB records, messages/notifications, and idempotency (no duplicate submissions on retries).
Test Data and Fixtures

Provide synthetic datasets for scholarships, students, providers; include edge cases (long names, unicode, right-to-left text, large file uploads).
Seed scripts for staging; teardown/cleanup procedures to keep environments stable.
Unique identifiers for parallel runs to avoid collisions.
CI/CD Integration

Parallelize suites by category; run unit/integration on each PR; E2E smoke on PR; full regression nightly; performance weekly; security weekly.
Flake management: retries with artifacts (video, HAR, screenshots, logs); quarantine list and deflake tasks.
Reporting and Exit Criteria

Outputs: HTML/JSON reports with trends, coverage per area, defects with repro steps and environment data, performance graphs, axe reports, visual diffs.
Pass criteria:
0 critical/blocked defects
Accessibility: 0 critical/serious axe violations
Visual: 0 unapproved diffs
Functional: ≥98% pass rate on P0/P1 E2E paths
Performance: meets thresholds above
Security: no exploitable high/critical findings
Execution Instructions for the QA Assistant

Produce the full test plan and coverage matrix first.
Then generate:
Frontend: sample Jest + React Testing Library tests for 3 core components; Playwright/Cypress spec files for 2 key flows; axe integration example.
Backend: Postman collection or REST-assured tests for 5 core endpoints; k6 script for the main read and write workloads; example SQL migration test.
E2E: 2 complete cross-browser specs (student journey, provider journey) with data setup/teardown.
Provide commands to run each suite locally and in CI, including environment variables and secrets management guidance.
Identify the top 5 flakiness risks and propose mitigations (network waits, test IDs, mock strategies, retry policies).
Call out any gaps or assumptions, and request missing inputs explicitly.
Placeholders to Fill Before Running

{APP_URL}, {API_BASE_URL}, {STAGING_URL}
{EMAIL_STUDENT}, {PASSWORD_STUDENT}, {EMAIL_PROVIDER}, {PASSWORD_PROVIDER}, {EMAIL_ADMIN}, {PASSWORD_ADMIN}
{TARGET_RPS}, {DURATION}, {RPS_SOAK}, {SOAK_DURATION}
Optional Quick-Smoke Variant (use when time-constrained)

Scope: login, scholarship search, application submit, provider publish.
Browsers: Chrome desktop and iOS Safari only.
Acceptance: 0 critical defects; axe serious=0; P95 API ≤150ms; visual diffs 0%.
Deliverables: 1-page plan, 4 E2E specs, 1 API collection, smoke performance script, brief report.
Use this prompt verbatim with your QA automation assistant, then iterate based on the generated gaps and environment feedback.